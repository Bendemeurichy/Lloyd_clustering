{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7298930b532cfc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Dask client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T12:12:15.285546Z",
     "start_time": "2024-04-25T12:12:12.926329Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "from dask.distributed import LocalCluster\n",
    "cluster = LocalCluster(n_workers=4,processes=True,\n",
    "    threads_per_worker=1)          # Fully-featured local Dask cluster\n",
    "client = cluster.get_client()\n",
    "client"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554c038b9067c18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T12:12:15.354844Z",
     "start_time": "2024-04-25T12:12:15.286538Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import algorithms.lloyd_clustering as lloyd"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7eca2dbb4d834339",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba41ca67703912c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T12:17:58.487237Z",
     "start_time": "2024-04-25T12:17:58.406794Z"
    }
   },
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate data for different center amounts\n",
    "for center_amount in range(2, 11):\n",
    "    X, y = make_blobs(n_samples=1000, centers=center_amount, n_features=2, random_state=42)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    np.savetxt(f'../data/data_center_{center_amount}.txt', X, fmt='%.8f')\n",
    "\n",
    "# Generate data for different dimension amounts\n",
    "for dimension_amount in range(2, 11):\n",
    "    X, y = make_blobs(n_samples=1000, centers=5, n_features=dimension_amount, random_state=42)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    np.savetxt(f'../data/data_dimension_{dimension_amount}.txt', X, fmt='%.8f')\n",
    "\n",
    "# Generate data for different sample amounts\n",
    "for sample_amount in range(1000, 10001, 1000):\n",
    "    X, y = make_blobs(n_samples=sample_amount, centers=5, n_features=2, random_state=42)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    np.savetxt(f'../data/data_sample_{sample_amount}.txt', X, fmt='%.8f')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b497008ca9f3fe",
   "metadata": {},
   "source": [
    "## Test the dask version with the dashboard to see if the code is running in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92510fc8a6bed24",
   "metadata": {},
   "source": [
    "lloyd_algorithm('../data/data_05.txt',5,True,3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9adeffdef726b08d",
   "metadata": {},
   "source": [
    "it's visibly parallel but the data is quite small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269d5afa18bffe6",
   "metadata": {},
   "source": [
    "# Run all versions of the algorithm.\n",
    "Use memray and timeit to measure performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f668b0cc626d6245",
   "metadata": {},
   "source": [
    "## Import all required extra packages for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64bd2e338a0a27",
   "metadata": {},
   "source": [
    "import logging\n",
    "import tqdm\n",
    "import timeit\n",
    "import memray\n",
    "import ast"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b1178358b80e805a",
   "metadata": {},
   "source": [
    "## Time benchmarks using timeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7774fbb01350c5bf",
   "metadata": {},
   "source": [
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def time_benchmark():\n",
    "    log.info('Starting time benchmark')\n",
    "    \n",
    "    for center_amount in range(2,11):\n",
    "        # Read the data from the file\n",
    "        with open(f'../data/data_center_{center_amount}.txt', encoding=\"utf-8\") as file:\n",
    "            filecontent = file.read()\n",
    "            points: list[tuple[float, ...]] = list(ast.literal_eval(filecontent))\n",
    "        \n",
    "        # Iterate 100 times to check means and error margin.\n",
    "        for i in range(0,100):\n",
    "            initial_centers= lloyd._k_means_plus_plus(center_amount, points)\n",
    "            \n",
    "            # Time the implementations\n",
    "            time_base = timeit.timeit(lambda: lloyd._k_means_base(points, initial_centers), number=1)\n",
    "            time_numpy = timeit.timeit(lambda: lloyd._k_means_numpy(points, initial_centers), number=1)\n",
    "            time_dask = timeit.timeit(lambda: lloyd._k_means_dask(points, initial_centers), number=1)\n",
    "            \n",
    "            log.info(f'saving results for center amount: {center_amount}, iteration: {i}')\n",
    "            np.savetxt(f'../output/output_center_{center_amount}.csv', f'{time_base},', fmt='%.8f')\n",
    "            np.savetxt(f'../output/output_center_{center_amount}.csv', f'{time_numpy},', fmt='%.8f')\n",
    "            np.savetxt(f'../output/output_center_{center_amount}.csv', f'{time_dask},', fmt='%.8f')\n",
    "\n",
    "    for dimensions in range(2,11):\n",
    "        #Read the data from the file\n",
    "        with open(f'../data/data_dimension_{dimensions}.txt'\n",
    "                \n",
    "        \n",
    "        "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067ed2b-84e9-496c-b49d-358ec62a40f5",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
